{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8723887",
   "metadata": {
    "papermill": {
     "duration": 0.002899,
     "end_time": "2026-01-29T00:26:59.585098",
     "exception": false,
     "start_time": "2026-01-29T00:26:59.582199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Vaguely unrelated note:\n",
    "Thank you to all the incredible women out there, who've helped us get to a day and age where we can celebrate women in data science. proud to be a woman in data science :D <3\n",
    "Alana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5cc7af",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-29T00:26:59.591653Z",
     "iopub.status.busy": "2026-01-29T00:26:59.590654Z",
     "iopub.status.idle": "2026-01-29T00:27:01.133841Z",
     "shell.execute_reply": "2026-01-29T00:27:01.132293Z"
    },
    "papermill": {
     "duration": 1.549197,
     "end_time": "2026-01-29T00:27:01.136405",
     "exception": false,
     "start_time": "2026-01-29T00:26:59.587208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>num_perimeters_0_5h</th>\n",
       "      <th>dt_first_last_0_5h</th>\n",
       "      <th>low_temporal_resolution_0_5h</th>\n",
       "      <th>area_first_ha</th>\n",
       "      <th>area_growth_abs_0_5h</th>\n",
       "      <th>area_growth_rel_0_5h</th>\n",
       "      <th>area_growth_rate_ha_per_h</th>\n",
       "      <th>log1p_area_first</th>\n",
       "      <th>log1p_growth</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_fit_r2_0_5h</th>\n",
       "      <th>alignment_cos</th>\n",
       "      <th>alignment_abs</th>\n",
       "      <th>cross_track_component</th>\n",
       "      <th>along_track_speed</th>\n",
       "      <th>event_start_hour</th>\n",
       "      <th>event_start_dayofweek</th>\n",
       "      <th>event_start_month</th>\n",
       "      <th>time_to_hit_hours</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10892457</td>\n",
       "      <td>3</td>\n",
       "      <td>4.265188</td>\n",
       "      <td>0</td>\n",
       "      <td>79.696304</td>\n",
       "      <td>2.875935</td>\n",
       "      <td>0.036086</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>4.390693</td>\n",
       "      <td>1.354787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886373</td>\n",
       "      <td>-0.054649</td>\n",
       "      <td>0.054649</td>\n",
       "      <td>-1.937219</td>\n",
       "      <td>-0.106026</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>18.892512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11757157</td>\n",
       "      <td>2</td>\n",
       "      <td>1.169918</td>\n",
       "      <td>0</td>\n",
       "      <td>8.946749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.297246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.568898</td>\n",
       "      <td>0.568898</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>22.048108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11945086</td>\n",
       "      <td>4</td>\n",
       "      <td>4.777526</td>\n",
       "      <td>0</td>\n",
       "      <td>106.482638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.677329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882385</td>\n",
       "      <td>0.882385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.888895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12044083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>67.631125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.228746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>60.953021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12052347</td>\n",
       "      <td>2</td>\n",
       "      <td>4.975273</td>\n",
       "      <td>0</td>\n",
       "      <td>35.632874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934634</td>\n",
       "      <td>0.934634</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>44.990274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  num_perimeters_0_5h  dt_first_last_0_5h  \\\n",
       "0  10892457                    3            4.265188   \n",
       "1  11757157                    2            1.169918   \n",
       "2  11945086                    4            4.777526   \n",
       "3  12044083                    1            0.000000   \n",
       "4  12052347                    2            4.975273   \n",
       "\n",
       "   low_temporal_resolution_0_5h  area_first_ha  area_growth_abs_0_5h  \\\n",
       "0                             0      79.696304              2.875935   \n",
       "1                             0       8.946749              0.000000   \n",
       "2                             0     106.482638              0.000000   \n",
       "3                             1      67.631125              0.000000   \n",
       "4                             0      35.632874              0.000000   \n",
       "\n",
       "   area_growth_rel_0_5h  area_growth_rate_ha_per_h  log1p_area_first  \\\n",
       "0              0.036086                   0.674281          4.390693   \n",
       "1              0.000000                   0.000000          2.297246   \n",
       "2              0.000000                   0.000000          4.677329   \n",
       "3              0.000000                   0.000000          4.228746   \n",
       "4              0.000000                   0.000000          3.600946   \n",
       "\n",
       "   log1p_growth  ...  dist_fit_r2_0_5h  alignment_cos  alignment_abs  \\\n",
       "0      1.354787  ...          0.886373      -0.054649       0.054649   \n",
       "1      0.000000  ...          0.000000      -0.568898       0.568898   \n",
       "2      0.000000  ...          0.000000       0.882385       0.882385   \n",
       "3      0.000000  ...          0.000000       0.000000       0.000000   \n",
       "4      0.000000  ...          0.000000       0.934634       0.934634   \n",
       "\n",
       "   cross_track_component  along_track_speed  event_start_hour  \\\n",
       "0              -1.937219          -0.106026                19   \n",
       "1              -0.000000          -0.000000                 4   \n",
       "2               0.000000           0.000000                22   \n",
       "3               0.000000           0.000000                20   \n",
       "4              -0.000000           0.000000                21   \n",
       "\n",
       "   event_start_dayofweek  event_start_month  time_to_hit_hours  event  \n",
       "0                      4                  5          18.892512      0  \n",
       "1                      4                  6          22.048108      1  \n",
       "2                      4                  8           0.888895      1  \n",
       "3                      5                  8          60.953021      0  \n",
       "4                      5                  7          44.990274      0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"/Users/OG1/Documents/wids-datathon-2026/multihead-lgb/data/train.csv\")\n",
    "test = pd.read_csv(\"/Users/OG1/Documents/wids-datathon-2026/multihead-lgb/data/test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5288d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T00:27:01.144318Z",
     "iopub.status.busy": "2026-01-29T00:27:01.143366Z",
     "iopub.status.idle": "2026-01-29T00:27:01.210503Z",
     "shell.execute_reply": "2026-01-29T00:27:01.209270Z"
    },
    "papermill": {
     "duration": 0.073256,
     "end_time": "2026-01-29T00:27:01.212602",
     "exception": false,
     "start_time": "2026-01-29T00:27:01.139346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: train_organized.csv\n",
      "Saved: test_organized.csv\n",
      "Train shape: (221, 45)\n",
      "Test shape: (95, 39)\n",
      "Train label non-null counts: {'prob_12h': 215, 'prob_24h': 196, 'prob_48h': 166, 'prob_72h': 69}\n"
     ]
    }
   ],
   "source": [
    "# organize the unsatisfying format of the original dataset.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "HORIZONS = [12, 24, 48, 72]\n",
    "\n",
    "def build_horizon_targets(df: pd.DataFrame, horizons=HORIZONS):\n",
    "    required = {\"event_id\", \"time_to_hit_hours\", \"event\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Train is missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"event_id\"] = pd.to_numeric(out[\"event_id\"], errors=\"raise\").astype(np.int64)\n",
    "    out[\"event\"] = pd.to_numeric(out[\"event\"], errors=\"raise\").astype(np.int64)\n",
    "    out[\"time_to_hit_hours\"] = pd.to_numeric(out[\"time_to_hit_hours\"], errors=\"raise\").astype(float)\n",
    "\n",
    "    t = out[\"time_to_hit_hours\"].values\n",
    "    e = out[\"event\"].values\n",
    "\n",
    "    for H in horizons:\n",
    "        unknown = (e == 0) & (t < H)\n",
    "\n",
    "        y = ((e == 1) & (t <= H)).astype(float)\n",
    "\n",
    "        y[unknown] = np.nan\n",
    "\n",
    "        out[f\"prob_{H}h\"] = y\n",
    "        out[f\"mask_{H}h\"] = (~unknown).astype(np.int8)\n",
    "\n",
    "    if out[\"event_id\"].duplicated().any():\n",
    "        dup = out.loc[out[\"event_id\"].duplicated(), \"event_id\"].iloc[0]\n",
    "        raise ValueError(f\"Duplicate event_id found in train: {dup}\")\n",
    "\n",
    "    for a, b in zip(horizons[:-1], horizons[1:]):\n",
    "        ma = out[f\"mask_{a}h\"].values.astype(bool)\n",
    "        mb = out[f\"mask_{b}h\"].values.astype(bool)\n",
    "        both = ma & mb\n",
    "\n",
    "        ya = out.loc[both, f\"prob_{a}h\"].values\n",
    "        yb = out.loc[both, f\"prob_{b}h\"].values\n",
    "\n",
    "        bad = np.where((~np.isnan(ya)) & (~np.isnan(yb)) & (ya > yb))[0]\n",
    "        if bad.size:\n",
    "            i = out.index[both][bad[0]]\n",
    "            raise ValueError(\n",
    "                f\"Monotonicity violated in labels at row index {i}: \"\n",
    "                f\"prob_{a}h={out.at[i, f'prob_{a}h']}, prob_{b}h={out.at[i, f'prob_{b}h']}\"\n",
    "            )\n",
    "\n",
    "    return out\n",
    "\n",
    "def organize_test(df: pd.DataFrame, horizons=HORIZONS):\n",
    "    out = df.copy()\n",
    "    if \"event_id\" not in out.columns:\n",
    "        raise KeyError(\"Test is missing required column: event_id\")\n",
    "\n",
    "    out[\"event_id\"] = pd.to_numeric(out[\"event_id\"], errors=\"raise\").astype(np.int64)\n",
    "\n",
    "    if out[\"event_id\"].duplicated().any():\n",
    "        dup = out.loc[out[\"event_id\"].duplicated(), \"event_id\"].iloc[0]\n",
    "        raise ValueError(f\"Duplicate event_id found in test: {dup}\")\n",
    "\n",
    "    for H in horizons:\n",
    "        out[f\"prob_{H}h\"] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "train_organized = build_horizon_targets(train)\n",
    "test_organized  = organize_test(test)\n",
    "\n",
    "label_cols = [f\"prob_{H}h\" for H in HORIZONS]\n",
    "mask_cols  = [f\"mask_{H}h\" for H in HORIZONS]\n",
    "\n",
    "train_cols_order = (\n",
    "    [\"event_id\"]\n",
    "    + [c for c in train_organized.columns if c not in ([\"event_id\"] + label_cols + mask_cols)]\n",
    "    + label_cols\n",
    "    + mask_cols\n",
    ")\n",
    "\n",
    "test_cols_order = (\n",
    "    [\"event_id\"]\n",
    "    + [c for c in test_organized.columns if c not in ([\"event_id\"] + label_cols)]\n",
    "    + label_cols\n",
    ")\n",
    "\n",
    "train_organized = train_organized[train_cols_order]\n",
    "test_organized  = test_organized[test_cols_order]\n",
    "\n",
    "train_organized.to_csv(\"train_organized.csv\", index=False)\n",
    "test_organized.to_csv(\"test_organized.csv\", index=False)\n",
    "\n",
    "print(\"Saved: train_organized.csv\")\n",
    "print(\"Saved: test_organized.csv\")\n",
    "print(\"Train shape:\", train_organized.shape)\n",
    "print(\"Test shape:\", test_organized.shape)\n",
    "print(\"Train label non-null counts:\", {c: int(train_organized[c].notna().sum()) for c in label_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d03960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T00:27:01.220222Z",
     "iopub.status.busy": "2026-01-29T00:27:01.219302Z",
     "iopub.status.idle": "2026-01-29T00:27:03.703310Z",
     "shell.execute_reply": "2026-01-29T00:27:03.701541Z"
    },
    "papermill": {
     "duration": 2.490458,
     "end_time": "2026-01-29T00:27:03.705756",
     "exception": false,
     "start_time": "2026-01-29T00:27:01.215298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: train_scaled.csv\n",
      "Saved: test_scaled.csv\n",
      "Scaled feature count: 34\n"
     ]
    }
   ],
   "source": [
    "#scaling. i know i use a tree based model, but i scaled it anyways incase i wanna try another model. :o)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "HORIZONS = (12, 24, 48, 72)\n",
    "\n",
    "train = pd.read_csv(\"train_organized.csv\")\n",
    "test = pd.read_csv(\"test_organized.csv\")\n",
    "\n",
    "label_cols = [f\"prob_{h}h\" for h in HORIZONS]\n",
    "mask_cols = [f\"mask_{h}h\" for h in HORIZONS]\n",
    "\n",
    "exclude_cols = {\"event_id\", \"time_to_hit_hours\", \"event\", *label_cols, *mask_cols}\n",
    "\n",
    "feature_cols = [c for c in train.columns if c not in exclude_cols]\n",
    "\n",
    "for c in feature_cols:\n",
    "    train[c] = pd.to_numeric(train[c], errors=\"coerce\")\n",
    "    if c in test.columns:\n",
    "        test[c] = pd.to_numeric(test[c], errors=\"coerce\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = train[feature_cols].astype(float).values\n",
    "X_test = test[feature_cols].astype(float).values\n",
    "\n",
    "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_test = np.nan_to_num(X_test, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_scaled = train.copy()\n",
    "test_scaled = test.copy()\n",
    "\n",
    "train_scaled[feature_cols] = X_train_scaled\n",
    "test_scaled[feature_cols] = X_test_scaled\n",
    "\n",
    "train_scaled.to_csv(\"train_scaled.csv\", index=False)\n",
    "test_scaled.to_csv(\"test_scaled.csv\", index=False)\n",
    "\n",
    "print(\"Saved: train_scaled.csv\")\n",
    "print(\"Saved: test_scaled.csv\")\n",
    "print(\"Scaled feature count:\", len(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5ea9b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T00:27:03.713405Z",
     "iopub.status.busy": "2026-01-29T00:27:03.712652Z",
     "iopub.status.idle": "2026-01-29T00:27:03.731319Z",
     "shell.execute_reply": "2026-01-29T00:27:03.730233Z"
    },
    "papermill": {
     "duration": 0.025079,
     "end_time": "2026-01-29T00:27:03.733555",
     "exception": false,
     "start_time": "2026-01-29T00:27:03.708476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining custom evluation method used in the competition.\n",
    "import numpy as np\n",
    "\n",
    "HORIZONS = (12.0, 24.0, 48.0, 72.0)\n",
    "\n",
    "def _to_numpy(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    return np.asarray(x)\n",
    "\n",
    "def harrell_c_index(time_to_hit_hours, event, risk_score):\n",
    "    t = _to_numpy(time_to_hit_hours).astype(float)\n",
    "    e = _to_numpy(event).astype(int)\n",
    "    r = _to_numpy(risk_score).astype(float)\n",
    "\n",
    "    n = t.shape[0]\n",
    "    conc = 0.0\n",
    "    ties = 0.0\n",
    "    comparable = 0.0\n",
    "\n",
    "    for i in range(n):\n",
    "        if e[i] != 1:\n",
    "            continue\n",
    "        ti = t[i]\n",
    "        ri = r[i]\n",
    "        for j in range(n):\n",
    "            if j == i:\n",
    "                continue\n",
    "            tj = t[j]\n",
    "            if ti < tj:\n",
    "                comparable += 1.0\n",
    "                rj = r[j]\n",
    "                if ri > rj:\n",
    "                    conc += 1.0\n",
    "                elif ri == rj:\n",
    "                    ties += 1.0\n",
    "\n",
    "    if comparable == 0.0:\n",
    "        return 0.5\n",
    "    return (conc + 0.5 * ties) / comparable\n",
    "\n",
    "def brier_at_horizon(time_to_hit_hours, event, prob_hit_by_h, H):\n",
    "    t = _to_numpy(time_to_hit_hours).astype(float)\n",
    "    e = _to_numpy(event).astype(int)\n",
    "    p = _to_numpy(prob_hit_by_h).astype(float)\n",
    "\n",
    "    valid = ~((e == 0) & (t < H))\n",
    "    if not np.any(valid):\n",
    "        return 0.25\n",
    "\n",
    "    hit_by_h = ((e == 1) & (t <= H)).astype(float)\n",
    "    y = hit_by_h[valid]\n",
    "    pv = p[valid]\n",
    "\n",
    "    pv = np.clip(pv, 0.0, 1.0)\n",
    "    return float(np.mean((pv - y) ** 2))\n",
    "\n",
    "def weighted_brier(time_to_hit_hours, event, prob_24h, prob_48h, prob_72h):\n",
    "    b24 = brier_at_horizon(time_to_hit_hours, event, prob_24h, 24.0)\n",
    "    b48 = brier_at_horizon(time_to_hit_hours, event, prob_48h, 48.0)\n",
    "    b72 = brier_at_horizon(time_to_hit_hours, event, prob_72h, 72.0)\n",
    "    return 0.3 * b24 + 0.4 * b48 + 0.3 * b72\n",
    "\n",
    "def hybrid_score(time_to_hit_hours, event, prob_24h, prob_48h, prob_72h, risk_score):\n",
    "    c = harrell_c_index(time_to_hit_hours, event, risk_score)\n",
    "    wb = weighted_brier(time_to_hit_hours, event, prob_24h, prob_48h, prob_72h)\n",
    "    return 0.3 * c + 0.7 * (1.0 - wb)\n",
    "\n",
    "def make_hybrid_callback(time_to_hit_hours, event, get_probs_and_risk, period=10, name=\"hybrid\"):\n",
    "    t = _to_numpy(time_to_hit_hours).astype(float)\n",
    "    e = _to_numpy(event).astype(int)\n",
    "\n",
    "    def _cb(env):\n",
    "        it = int(getattr(env, \"iteration\", 0))\n",
    "        if it % int(period) != 0 and it != 0:\n",
    "            return\n",
    "        out = get_probs_and_risk(env)\n",
    "        p24 = _to_numpy(out[\"prob_24h\"]).astype(float)\n",
    "        p48 = _to_numpy(out[\"prob_48h\"]).astype(float)\n",
    "        p72 = _to_numpy(out[\"prob_72h\"]).astype(float)\n",
    "        rs  = _to_numpy(out[\"risk_score\"]).astype(float)\n",
    "        val = hybrid_score(t, e, p24, p48, p72, rs)\n",
    "        print(f\"[{name}] iter={it}  value={val:.6f}\")\n",
    "\n",
    "    return _cb\n",
    "\n",
    "def make_brier_feval(H):\n",
    "    H = float(H)\n",
    "    def _feval(preds, dataset):\n",
    "        t = _to_numpy(dataset.get_field(\"time_to_hit_hours\")).astype(float)\n",
    "        e = _to_numpy(dataset.get_label()).astype(int)\n",
    "        p = _to_numpy(preds).astype(float)\n",
    "        b = brier_at_horizon(t, e, p, H)\n",
    "        return (f\"brier_{int(H)}h\", b, False)\n",
    "    return _feval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53dadf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T00:27:03.741573Z",
     "iopub.status.busy": "2026-01-29T00:27:03.740513Z",
     "iopub.status.idle": "2026-01-29T00:27:11.883733Z",
     "shell.execute_reply": "2026-01-29T00:27:11.882856Z"
    },
    "papermill": {
     "duration": 8.150095,
     "end_time": "2026-01-29T00:27:11.886211",
     "exception": false,
     "start_time": "2026-01-29T00:27:03.736116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m HORIZONS \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m72\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "HORIZONS = (12, 24, 48, 72)\n",
    "\n",
    "def _to_numpy(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    return np.asarray(x)\n",
    "\n",
    "def harrell_c_index(time_to_hit_hours, event, risk_score):\n",
    "    t = _to_numpy(time_to_hit_hours).astype(float)\n",
    "    e = _to_numpy(event).astype(int)\n",
    "    r = _to_numpy(risk_score).astype(float)\n",
    "\n",
    "    n = t.shape[0]\n",
    "    conc = 0.0\n",
    "    ties = 0.0\n",
    "    comparable = 0.0\n",
    "\n",
    "    for i in range(n):\n",
    "        if e[i] != 1:\n",
    "            continue\n",
    "        ti = t[i]\n",
    "        ri = r[i]\n",
    "        for j in range(n):\n",
    "            if j == i:\n",
    "                continue\n",
    "            tj = t[j]\n",
    "            if ti < tj:\n",
    "                comparable += 1.0\n",
    "                rj = r[j]\n",
    "                if ri > rj:\n",
    "                    conc += 1.0\n",
    "                elif ri == rj:\n",
    "                    ties += 1.0\n",
    "\n",
    "    if comparable == 0.0:\n",
    "        return 0.5\n",
    "    return (conc + 0.5 * ties) / comparable\n",
    "\n",
    "def brier_at_horizon(time_to_hit_hours, event, prob_hit_by_h, H):\n",
    "    t = _to_numpy(time_to_hit_hours).astype(float)\n",
    "    e = _to_numpy(event).astype(int)\n",
    "    p = _to_numpy(prob_hit_by_h).astype(float)\n",
    "\n",
    "    valid = ~((e == 0) & (t < H))\n",
    "    if not np.any(valid):\n",
    "        return 0.25\n",
    "\n",
    "    hit_by_h = ((e == 1) & (t <= H)).astype(float)\n",
    "    y = hit_by_h[valid]\n",
    "    pv = np.clip(p[valid], 0.0, 1.0)\n",
    "    return float(np.mean((pv - y) ** 2))\n",
    "\n",
    "def weighted_brier(time_to_hit_hours, event, prob_24h, prob_48h, prob_72h):\n",
    "    b24 = brier_at_horizon(time_to_hit_hours, event, prob_24h, 24.0)\n",
    "    b48 = brier_at_horizon(time_to_hit_hours, event, prob_48h, 48.0)\n",
    "    b72 = brier_at_horizon(time_to_hit_hours, event, prob_72h, 72.0)\n",
    "    return 0.3 * b24 + 0.4 * b48 + 0.3 * b72\n",
    "\n",
    "def hybrid_score(time_to_hit_hours, event, prob_24h, prob_48h, prob_72h, risk_score):\n",
    "    c = harrell_c_index(time_to_hit_hours, event, risk_score)\n",
    "    wb = weighted_brier(time_to_hit_hours, event, prob_24h, prob_48h, prob_72h)\n",
    "    return 0.3 * c + 0.7 * (1.0 - wb)\n",
    "\n",
    "def monotone_probs(p12, p24, p48, p72):\n",
    "    p12 = np.clip(p12, 0.0, 1.0)\n",
    "    p24 = np.clip(p24, 0.0, 1.0)\n",
    "    p48 = np.clip(p48, 0.0, 1.0)\n",
    "    p72 = np.clip(p72, 0.0, 1.0)\n",
    "    p24 = np.maximum(p24, p12)\n",
    "    p48 = np.maximum(p48, p24)\n",
    "    p72 = np.maximum(p72, p48)\n",
    "    return p12, p24, p48, p72\n",
    "\n",
    "train = pd.read_csv(\"train_scaled.csv\")\n",
    "test = pd.read_csv(\"test_scaled.csv\")\n",
    "\n",
    "prob_cols = [f\"prob_{h}h\" for h in HORIZONS]\n",
    "mask_cols = [f\"mask_{h}h\" for h in HORIZONS]\n",
    "exclude = {\"event_id\", \"time_to_hit_hours\", \"event\", *prob_cols, *mask_cols}\n",
    "\n",
    "feature_cols = [c for c in train.columns if c not in exclude]\n",
    "X_all = train[feature_cols].astype(float).values\n",
    "X_test = test[feature_cols].astype(float).values\n",
    "\n",
    "t_all = train[\"time_to_hit_hours\"].astype(float).values\n",
    "e_all = train[\"event\"].astype(int).values\n",
    "\n",
    "idx = np.arange(len(train))\n",
    "idx_tr, idx_va = train_test_split(idx, test_size=0.2, random_state=42, stratify=e_all)\n",
    "\n",
    "X_tr_all, X_va_all = X_all[idx_tr], X_all[idx_va]\n",
    "t_va, e_va = t_all[idx_va], e_all[idx_va]\n",
    "\n",
    "base_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"learning_rate\": 0.043,\n",
    "    \"num_leaves\": 42,\n",
    "    \"min_data_in_leaf\": 32,\n",
    "    \"feature_fraction\": 0.73,\n",
    "    \"bagging_fraction\": 0.86,\n",
    "    \"max_depth\":2,\n",
    "    \"bagging_freq\": 2,\n",
    "    \"lambda_l2\": 0.0,\n",
    "    \"lamda_l1\":0.0,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"force_col_wise\": True,\n",
    "}\n",
    "\n",
    "def make_dataset_for_h(h):\n",
    "    y = train[f\"prob_{h}h\"].values\n",
    "    m = ~np.isnan(y)\n",
    "    m_tr = m[idx_tr]\n",
    "    m_va = m[idx_va]\n",
    "    X_tr = X_all[idx_tr][m_tr]\n",
    "    y_tr = y[idx_tr][m_tr].astype(float)\n",
    "    X_va = X_all[idx_va][m_va]\n",
    "    y_va = y[idx_va][m_va].astype(float)\n",
    "    dtr = lgb.Dataset(X_tr, label=y_tr, feature_name=feature_cols, free_raw_data=False)\n",
    "    dva = lgb.Dataset(X_va, label=y_va, feature_name=feature_cols, free_raw_data=False)\n",
    "    return dtr, dva, m_va\n",
    "\n",
    "dtr12, dva12, mva12 = make_dataset_for_h(12)\n",
    "dtr24, dva24, mva24 = make_dataset_for_h(24)\n",
    "dtr48, dva48, mva48 = make_dataset_for_h(48)\n",
    "dtr72, dva72, mva72 = make_dataset_for_h(72)\n",
    "\n",
    "b12 = lgb.Booster(params=base_params, train_set=dtr12)\n",
    "b24 = lgb.Booster(params=base_params, train_set=dtr24)\n",
    "b48 = lgb.Booster(params=base_params, train_set=dtr48)\n",
    "b72 = lgb.Booster(params=base_params, train_set=dtr72)\n",
    "\n",
    "max_rounds = 5000\n",
    "patience = 200\n",
    "print_every = 10\n",
    "\n",
    "best_iter = 0\n",
    "best_score = -1e18\n",
    "since_best = 0\n",
    "best_models = None\n",
    "\n",
    "for it in range(1, max_rounds + 1):\n",
    "    b12.update()\n",
    "    b24.update()\n",
    "    b48.update()\n",
    "    b72.update()\n",
    "\n",
    "    if it % print_every == 0 or it == 1:\n",
    "        p12 = b12.predict(X_va_all, num_iteration=it)\n",
    "        p24 = b24.predict(X_va_all, num_iteration=it)\n",
    "        p48 = b48.predict(X_va_all, num_iteration=it)\n",
    "        p72 = b72.predict(X_va_all, num_iteration=it)\n",
    "        p12, p24, p48, p72 = monotone_probs(p12, p24, p48, p72)\n",
    "\n",
    "        risk = 0.3 * p24 + 0.4 * p48 + 0.3 * p72\n",
    "        score = hybrid_score(t_va, e_va, p24, p48, p72, risk)\n",
    "\n",
    "        brier24 = brier_at_horizon(t_va, e_va, p24, 24.0)\n",
    "        brier48 = brier_at_horizon(t_va, e_va, p48, 48.0)\n",
    "        brier72 = brier_at_horizon(t_va, e_va, p72, 72.0)\n",
    "        cidx = harrell_c_index(t_va, e_va, risk)\n",
    "\n",
    "        print(f\"iter={it}  hybrid={score:.6f}  cindex={cidx:.6f}  wbrier={0.3*brier24+0.4*brier48+0.3*brier72:.6f}  b24={brier24:.6f}  b48={brier48:.6f}  b72={brier72:.6f}\")\n",
    "\n",
    "        if score > best_score + 1e-12:\n",
    "            best_score = score\n",
    "            best_iter = it\n",
    "            since_best = 0\n",
    "            best_models = (b12.model_to_string(num_iteration=it),\n",
    "                           b24.model_to_string(num_iteration=it),\n",
    "                           b48.model_to_string(num_iteration=it),\n",
    "                           b72.model_to_string(num_iteration=it))\n",
    "        else:\n",
    "            since_best += print_every\n",
    "            if since_best >= patience:\n",
    "                break\n",
    "\n",
    "if best_models is None:\n",
    "    raise RuntimeError(\"No best model snapshot captured.\")\n",
    "\n",
    "b12_best = lgb.Booster(model_str=best_models[0])\n",
    "b24_best = lgb.Booster(model_str=best_models[1])\n",
    "b48_best = lgb.Booster(model_str=best_models[2])\n",
    "b72_best = lgb.Booster(model_str=best_models[3])\n",
    "\n",
    "print(f\"Best iter={best_iter}  best_hybrid={best_score:.6f}\")\n",
    "\n",
    "def train_full(h):\n",
    "    y = train[f\"prob_{h}h\"].values\n",
    "    m = ~np.isnan(y)\n",
    "    X = X_all[m]\n",
    "    yy = y[m].astype(float)\n",
    "    dtr = lgb.Dataset(X, label=yy, feature_name=feature_cols, free_raw_data=False)\n",
    "    booster = lgb.Booster(params=base_params, train_set=dtr)\n",
    "    for _ in range(best_iter):\n",
    "        booster.update()\n",
    "    return booster\n",
    "\n",
    "b12_full = train_full(12)\n",
    "b24_full = train_full(24)\n",
    "b48_full = train_full(48)\n",
    "b72_full = train_full(72)\n",
    "\n",
    "p12 = b12_full.predict(X_test)\n",
    "p24 = b24_full.predict(X_test)\n",
    "p48 = b48_full.predict(X_test)\n",
    "p72 = b72_full.predict(X_test)\n",
    "p12, p24, p48, p72 = monotone_probs(p12, p24, p48, p72)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"event_id\": test[\"event_id\"].astype(np.int64).values,\n",
    "    \"prob_12h\": p12.astype(float),\n",
    "    \"prob_24h\": p24.astype(float),\n",
    "    \"prob_48h\": p48.astype(float),\n",
    "    \"prob_72h\": p72.astype(float),\n",
    "})\n",
    "\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved: submission.csv\")\n",
    "print(sub.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15407763,
     "sourceId": 125681,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.406275,
   "end_time": "2026-01-29T00:27:12.911215",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-29T00:26:55.504940",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
